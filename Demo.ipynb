{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://192.168.104.50:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://192.168.104.50:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch import nn\n",
    "import torch\n",
    "import random\n",
    "from d2l import torch as d2l\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "# datasets = list_datasets()\n",
    "# print(\"Number of datasets in the Datasets library: \", len(datasets), \"\\n\\n\")\n",
    "\n",
    "# # 数据集列表\n",
    "# pprint(datasets, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ubutnu/nvmessd/DeepLearning/datasets/sradc___parquet/sradc--chunked-wikipedia20220301en-bookcorpusopen-2e9ae21627579891/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('sradc/chunked-wikipedia20220301en-bookcorpusopen',cache_dir='~/nvmessd/DeepLearning/datasets/',split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizerFast\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_next_sentence(sentence, next_sentence, paragraphs):\n",
    "    if random.random() < 0.5:\n",
    "        is_next = True\n",
    "    else:\n",
    "        # paragraphs是三重列表的嵌套\n",
    "        next_sentence = random.choice(random.choice(paragraphs))\n",
    "        is_next = False\n",
    "    return sentence, next_sentence, is_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n",
    "    nsp_data_from_paragraph = []\n",
    "    for i in range(len(paragraph) - 1):\n",
    "        tokens_a, tokens_b, is_next = _get_next_sentence(\n",
    "            paragraph[i], paragraph[i + 1], paragraphs)\n",
    "        # 考虑1个'<cls>'词元和2个'<sep>'词元\n",
    "        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n",
    "            continue\n",
    "        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "        nsp_data_from_paragraph.append((tokens, segments, is_next))\n",
    "    return nsp_data_from_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # 大写字母转换为小写字母\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "# def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n",
    "#                         vocab):\n",
    "#     # 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的“<mask>”或随机词元\n",
    "#     mlm_input_tokens = [token for token in tokens]\n",
    "#     pred_positions_and_labels = []\n",
    "#     # 打乱后用于在遮蔽语言模型任务中获取15%的随机词元进行预测\n",
    "#     random.shuffle(candidate_pred_positions)\n",
    "#     for mlm_pred_position in candidate_pred_positions:\n",
    "#         if len(pred_positions_and_labels) >= num_mlm_preds:\n",
    "#             break\n",
    "#         masked_token = None\n",
    "#         # 80%的时间：将词替换为“<mask>”词元\n",
    "#         if random.random() < 0.8:\n",
    "#             masked_token = '<mask>'\n",
    "#         else:\n",
    "#             # 10%的时间：保持词不变\n",
    "#             if random.random() < 0.5:\n",
    "#                 masked_token = tokens[mlm_pred_position]\n",
    "#             # 10%的时间：用随机词替换该词\n",
    "#             else:\n",
    "#                 masked_token = random.choice(vocab.idx_to_token)\n",
    "#         mlm_input_tokens[mlm_pred_position] = masked_token\n",
    "#         pred_positions_and_labels.append(\n",
    "#             (mlm_pred_position, tokens[mlm_pred_position]))\n",
    "#     return mlm_input_tokens, pred_positions_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "# def _get_mlm_data_from_tokens(tokens, vocab):\n",
    "#     candidate_pred_positions = []\n",
    "#     # tokens是一个字符串列表\n",
    "#     for i, token in enumerate(tokens):\n",
    "#         # 在遮蔽语言模型任务中不会预测特殊词元\n",
    "#         if token in ['<cls>', '<sep>']:\n",
    "#             continue\n",
    "#         candidate_pred_positions.append(i)\n",
    "#     # 遮蔽语言模型任务中预测15%的随机词元\n",
    "#     num_mlm_preds = max(1, round(len(tokens) * 0.15))\n",
    "#     mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n",
    "#         tokens, candidate_pred_positions, num_mlm_preds, vocab)\n",
    "#     pred_positions_and_labels = sorted(pred_positions_and_labels,\n",
    "#                                        key=lambda x: x[0])\n",
    "#     pred_positions = [v[0] for v in pred_positions_and_labels]\n",
    "#     mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n",
    "#     return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _pad_bert_inputs(examples, max_len, vocab):\n",
    "    max_num_mlm_preds = round(max_len * 0.15)\n",
    "    all_token_ids, all_segments, valid_lens,  = [], [], []\n",
    "    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n",
    "    nsp_labels = []\n",
    "    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n",
    "         is_next) in examples:\n",
    "        all_token_ids.append(torch.tensor(token_ids + [vocab['<pad>']] * (\n",
    "            max_len - len(token_ids)), dtype=torch.long))\n",
    "        all_segments.append(torch.tensor(segments + [0] * (\n",
    "            max_len - len(segments)), dtype=torch.long))\n",
    "        # valid_lens不包括'<pad>'的计数\n",
    "        valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))\n",
    "        all_pred_positions.append(torch.tensor(pred_positions + [0] * (\n",
    "            max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n",
    "        # 填充词元的预测将通过乘以0权重在损失中过滤掉\n",
    "        all_mlm_weights.append(\n",
    "            torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n",
    "                max_num_mlm_preds - len(pred_positions)),\n",
    "                dtype=torch.float32))\n",
    "        all_mlm_labels.append(torch.tensor(mlm_pred_label_ids + [0] * (\n",
    "            max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.long))\n",
    "        nsp_labels.append(torch.tensor(is_next, dtype=torch.long))\n",
    "    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n",
    "            all_mlm_weights, all_mlm_labels, nsp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs= dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraphs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_mask(tokens,max_len):\n",
    "    tokens = tokens.split(' ')\n",
    "        # 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的“<mask>”或随机词元\n",
    "    mlm_input_tokens = [token for token in tokens]\n",
    "    pred_positions_and_labels = []\n",
    "    candidate_pred_positions = [i for i in range(len(tokens))]\n",
    "    num_mlm_preds = max(1, round(max_len* 0.15))\n",
    "    # 打乱后用于在遮蔽语言模型任务中获取15%的随机词元进行预测\n",
    "    random.shuffle(candidate_pred_positions)\n",
    "    for mlm_pred_position in candidate_pred_positions:\n",
    "        if len(pred_positions_and_labels) >= num_mlm_preds:\n",
    "            break\n",
    "        masked_token = None\n",
    "        # 80%的时间：将词替换为“<mask>”词元\n",
    "        if random.random() < 0.8:\n",
    "            masked_token = '[MASK]'\n",
    "        else:\n",
    "            # 10%的时间：保持词不变\n",
    "           #if random.random() < 0.5:\n",
    "            masked_token = tokens[mlm_pred_position]\n",
    "            # 10%的时间：用随机词替换该词\n",
    "            # else:\n",
    "            #     masked_token = random.choice(vocab.idx_to_token)\n",
    "        mlm_input_tokens[mlm_pred_position] = masked_token\n",
    "        pred_positions_and_labels.append(\n",
    "            (mlm_pred_position, tokens[mlm_pred_position]))\n",
    "    return mlm_input_tokens, pred_positions_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_mlm_data_from_tokens(tokens,max_len):\n",
    "    # candidate_pred_positions = []\n",
    "    # # tokens是一个字符串列表\n",
    "    # for i, token in enumerate(tokens):\n",
    "    #     # 在遮蔽语言模型任务中不会预测特殊词元\n",
    "    #     if token in ['<cls>', '<sep>']:\n",
    "    #         continue\n",
    "    #     candidate_pred_positions.append(i)\n",
    "    # 遮蔽语言模型任务中预测15%的随机词元\n",
    "    mlm_input_tokens, pred_positions_and_labels = replace_mask(tokens,max_len)\n",
    "    pred_positions_and_labels = sorted(pred_positions_and_labels,\n",
    "                                       key=lambda x: x[0])\n",
    "    pred_positions = [v[0] for v in pred_positions_and_labels]\n",
    "    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n",
    "    return mlm_input_tokens, pred_positions,mlm_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a985ab9f24a3461dbb9a44de19c6370e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33536113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb Cell 16\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m tqdm(dataset[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     sample \u001b[39m=\u001b[39msample\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     token\u001b[39m.\u001b[39mappend(get_mlm_data_from_tokens(sample,\u001b[39m1024\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# dataset['text']\u001b[39;00m\n",
      "\u001b[1;32m/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mlm_data_from_tokens\u001b[39m(tokens,max_len):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# candidate_pred_positions = []\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# # tokens是一个字符串列表\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m#     candidate_pred_positions.append(i)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# 遮蔽语言模型任务中预测15%的随机词元\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     mlm_input_tokens, pred_positions_and_labels \u001b[39m=\u001b[39m replace_mask(tokens,max_len)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     pred_positions_and_labels \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(pred_positions_and_labels,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                                        key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     pred_positions \u001b[39m=\u001b[39m [v[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pred_positions_and_labels]\n",
      "\u001b[1;32m/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的“<mask>”或随机词元\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m mlm_input_tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m pred_positions_and_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244617075313436227d/home/ubutnu/nvmessd/DeepLearning/Demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m candidate_pred_positions \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tokens))]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "file_count=0\n",
    "token = []\n",
    "#front = [x.replace('\\n', '').split(' ') for x in paragraphs[:10]]\n",
    "# front = paragraphs[0].replace('\\n', '')\n",
    "for sample in tqdm(dataset['text']):\n",
    "    sample =sample.replace('\\n', '')\n",
    "    token.append(get_mlm_data_from_tokens(sample,1024))\n",
    "\n",
    "# dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wiki_book_Dataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, text,max_len): \n",
    "        self.text=text\n",
    "        self.max_len=max_len\n",
    "        self.max_num_mlm_preds = round(max_len * 0.15)\n",
    "        #self.rand_MASk=rand_MASk()\n",
    "        # if rand_MASk is None:\n",
    "        #     self.text=text\n",
    "        # else:\n",
    "        #     self.text=rand_MASk(text)\n",
    "\n",
    "    \n",
    "    def __len__(self): \n",
    "        # return the number of samples \n",
    "        return len(self.text)\n",
    " \n",
    "    def __getitem__(self, index): \n",
    "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
    "        #all_token_ids,all_pred_positions, all_mlm_labels=[], [],[]\n",
    "        #text_mask, pred_positions,labels = get_mlm_data_from_tokens(self.text[index],self.max_len)\n",
    "        # all_token_ids.append(text_mask + ['[PAD]'] * (\n",
    "        #     self.max_len - len(text_mask)))\n",
    "        # # text_mask=tokenizer.encode(text_mask,return_tensors=\"pt\",padding='max_length',max_length=self.max_len)\n",
    "        # all_pred_positions.append(torch.tensor(pred_positions + [0] * (self.max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n",
    "        # all_mlm_labels.append((labels + [0] * (\n",
    "        #     self.max_num_mlm_preds - len(labels))))\n",
    "        # labels=tokenizer.encode(labels,return_tensors=\"pt\",padding='max_length',max_length=self.max_num_mlm_preds)\n",
    "        return self.text[index]\n",
    "    # candidate_pred_positions = []\n",
    "    # # tokens是一个字符串列表\n",
    "    # for i, token in enumerate(tokens):\n",
    "    #     # 在遮蔽语言模型任务中不会预测特殊词元\n",
    "    #     if token in ['<cls>', '<sep>']:\n",
    "    #         continue\n",
    "    #     candidate_pred_positions.append(i)\n",
    "    # 遮蔽语言模型任务中预测15%的随机词元\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=512\n",
    "train_dataset=Wiki_book_Dataset(dataset['text'],max_len)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128,num_workers=8,shuffle=True)\n",
    "# inputs = tokenizer(toke[0],return_tensors=\"pt\")\n",
    "# model.train()\n",
    "# output = model(**inputs)\n",
    "# #example_text = tokenizer.decode(inputs.input_ids[0])\n",
    "# #tokenizer.get_special_tokens_mask(inputs.tokens_id_0)\n",
    "# inputs,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_mask, pred_positions,labels = get_mlm_data_from_tokens(dataset['text'][0],256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(text_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64,num_workers=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "for i,X in enumerate(train_loader):\n",
    "    if i >1:\n",
    "        break\n",
    "    #print(X[0])\n",
    "    print(tokenizer.batch_encode_plus(X,return_tensors=\"pt\",padding='max_length',max_length=512,truncation=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs,max_len):\n",
    "  # 通过Dataset类获取训练和验证集\n",
    "    #train, val = Dataset(train_data), Dataset(val_data)\n",
    "    train_dataset=Wiki_book_Dataset(train_data,max_len)\n",
    "    # DataLoader根据batch_size获取数据，训练时选择打乱样本\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64,num_workers=4,shuffle=False)\n",
    "  # 判断是否使用GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    # 开始进入训练循环\n",
    "    for epoch_num in range(epochs):\n",
    "      # 定义两个变量，用于存储训练集的准确率和损失\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "      # 进度条函数tqdm\n",
    "            for train_input, train_label in tqdm(train_loader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        # 通过模型得到输出\n",
    "                output = model(input_id, mask)\n",
    "                # 计算损失\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                # 计算精度\n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "        # 模型更新\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            # ------ 验证模型 -----------\n",
    "            # 定义两个变量，用于存储验证集的准确率和损失\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "      # 不需要计算梯度\n",
    "            with torch.no_grad():\n",
    "                # 循环获取数据集，并用训练好的模型进行验证\n",
    "                for val_input, val_label in val_dataloader:\n",
    "          # 如果有GPU，则使用GPU，接下来的操作同训练\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "  \n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'''Epochs: {epoch_num + 1} \n",
    "              | Train Loss: {total_loss_train / len(train_data): .3f} \n",
    "              | Train Accuracy: {total_acc_train / len(train_data): .3f} \n",
    "              | Val Loss: {total_loss_val / len(val_data): .3f} \n",
    "              | Val Accuracy: {total_acc_val / len(val_data): .3f}''')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
